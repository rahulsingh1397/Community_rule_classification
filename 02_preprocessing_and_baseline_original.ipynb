{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jigsaw Reddit Competition - Preprocessing & Baseline Model\n",
    "\n",
    "This notebook implements:\n",
    "1. Robust Cross-Validation using StratifiedGroupKFold\n",
    "2. Reddit-Specific Text Preprocessing\n",
    "3. Feature Engineering with Rule Embeddings\n",
    "4. Baseline Model with TF-IDF + LightGBM\n",
    "5. Comprehensive Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Study\\Kaggle\\Jigsaw - Agile Community Rules Classification\\jigsaw_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import lightgbm as lgb\n",
    "\n",
    "# NLP libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2029, 9)\n",
      "Test shape: (10, 8)\n",
      "Unique rules in train: 2\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('Data/train.csv')\n",
    "test_df = pd.read_csv('Data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Unique rules in train: {train_df['rule'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reddit Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reddit_text(text):\n",
    "    \"\"\"Clean Reddit-specific formatting\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Handle Reddit markdown\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)  # Bold\n",
    "    text = re.sub(r'\\*(.*?)\\*', r'\\1', text)      # Italic\n",
    "    text = re.sub(r'~~(.*?)~~', r'\\1', text)      # Strikethrough\n",
    "    \n",
    "    # Handle quotes\n",
    "    text = re.sub(r'^&gt;.*$', '[QUOTE]', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Normalize mentions\n",
    "    text = re.sub(r'/u/\\w+', '[USER]', text)\n",
    "    text = re.sub(r'/r/\\w+', '[SUBREDDIT]', text)\n",
    "    \n",
    "    # Handle URLs\n",
    "    text = re.sub(r'http[s]?://\\S+', '[URL]', text)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "train_df['body_cleaned'] = train_df['body'].apply(clean_reddit_text)\n",
    "test_df['body_cleaned'] = test_df['body'].apply(clean_reddit_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed\n"
     ]
    }
   ],
   "source": [
    "# Text features\n",
    "def get_text_features(text):\n",
    "    \"\"\"Extract text statistics\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return {'char_count': 0, 'word_count': 0, 'exclamation_count': 0}\n",
    "    \n",
    "    text = str(text)\n",
    "    return {\n",
    "        'char_count': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'exclamation_count': text.count('!'),\n",
    "        'question_count': text.count('?'),\n",
    "        'caps_ratio': sum(1 for c in text if c.isupper()) / len(text) if text else 0\n",
    "    }\n",
    "\n",
    "# Apply text features\n",
    "train_text_features = pd.DataFrame(train_df['body'].apply(get_text_features).tolist())\n",
    "test_text_features = pd.DataFrame(test_df['body'].apply(get_text_features).tolist())\n",
    "\n",
    "# Encode subreddit\n",
    "subreddit_encoder = LabelEncoder()\n",
    "train_df['subreddit_encoded'] = subreddit_encoder.fit_transform(train_df['subreddit'])\n",
    "test_df['subreddit_encoded'] = subreddit_encoder.transform(test_df['subreddit'])\n",
    "\n",
    "print(\"Feature engineering completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup StratifiedGroupKFold\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "groups = train_df['rule']\n",
    "y = train_df['rule_violation']\n",
    "\n",
    "cv_folds = list(sgkf.split(train_df, y, groups))\n",
    "print(f\"Created {len(cv_folds)} folds\")\n",
    "\n",
    "# Analyze folds\n",
    "for i, (train_idx, val_idx) in enumerate(cv_folds):\n",
    "    train_rules = set(train_df.iloc[train_idx]['rule'])\n",
    "    val_rules = set(train_df.iloc[val_idx]['rule'])\n",
    "    print(f\"Fold {i+1}: Train rules: {train_rules}, Val rules: {val_rules}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizers\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char', ngram_range=(2, 4), max_features=10000\n",
    ")\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    analyzer='word', ngram_range=(1, 2), max_features=20000, stop_words='english'\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "train_char_tfidf = char_vectorizer.fit_transform(train_df['body_cleaned'])\n",
    "train_word_tfidf = word_vectorizer.fit_transform(train_df['body_cleaned'])\n",
    "\n",
    "test_char_tfidf = char_vectorizer.transform(test_df['body_cleaned'])\n",
    "test_word_tfidf = word_vectorizer.transform(test_df['body_cleaned'])\n",
    "\n",
    "print(f\"Character TF-IDF shape: {train_char_tfidf.shape}\")\n",
    "print(f\"Word TF-IDF shape: {train_word_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine all features\n",
    "train_combined = hstack([\n",
    "    train_char_tfidf,\n",
    "    train_word_tfidf,\n",
    "    train_text_features.values,\n",
    "    train_df[['subreddit_encoded']].values\n",
    "])\n",
    "\n",
    "test_combined = hstack([\n",
    "    test_char_tfidf,\n",
    "    test_word_tfidf,\n",
    "    test_text_features.values,\n",
    "    test_df[['subreddit_encoded']].values\n",
    "])\n",
    "\n",
    "print(f\"Combined training features shape: {train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LightGBM Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Cross-validation training\n",
    "oof_predictions = np.zeros(len(train_df))\n",
    "fold_scores = []\n",
    "models = []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv_folds):\n",
    "    print(f\"Training fold {fold_idx + 1}...\")\n",
    "    \n",
    "    X_train_fold = train_combined[train_idx]\n",
    "    X_val_fold = train_combined[val_idx]\n",
    "    y_train_fold = y.iloc[train_idx]\n",
    "    y_val_fold = y.iloc[val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    train_data = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "    val_data = lgb.Dataset(X_val_fold, label=y_val_fold)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    val_pred = model.predict(X_val_fold, num_iteration=model.best_iteration)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # Score\n",
    "    fold_auc = roc_auc_score(y_val_fold, val_pred)\n",
    "    fold_scores.append(fold_auc)\n",
    "    models.append(model)\n",
    "    \n",
    "    print(f\"Fold {fold_idx + 1} AUC: {fold_auc:.4f}\")\n",
    "\n",
    "# Overall score\n",
    "overall_auc = roc_auc_score(y, oof_predictions)\n",
    "print(f\"\\nOverall CV AUC: {overall_auc:.4f} (+/- {np.std(fold_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# CV scores\n",
    "axes[0].bar(range(1, len(fold_scores)+1), fold_scores)\n",
    "axes[0].set_title('Cross-Validation AUC Scores')\n",
    "axes[0].set_xlabel('Fold')\n",
    "axes[0].set_ylabel('AUC')\n",
    "\n",
    "# Prediction distribution\n",
    "axes[1].hist(oof_predictions[y==0], alpha=0.7, label='Non-violation', bins=50)\n",
    "axes[1].hist(oof_predictions[y==1], alpha=0.7, label='Violation', bins=50)\n",
    "axes[1].set_title('Prediction Distribution')\n",
    "axes[1].set_xlabel('Predicted Probability')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBaseline Model Summary:\")\n",
    "print(f\"- Cross-validation AUC: {overall_auc:.4f}\")\n",
    "print(f\"- Standard deviation: {np.std(fold_scores):.4f}\")\n",
    "print(f\"- Feature count: {train_combined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test predictions\n",
    "test_predictions = np.zeros(len(test_df))\n",
    "\n",
    "for model in models:\n",
    "    test_pred = model.predict(test_combined, num_iteration=model.best_iteration)\n",
    "    test_predictions += test_pred / len(models)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': test_df.index,\n",
    "    'rule_violation': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('baseline_submission.csv', index=False)\n",
    "print(f\"Submission saved with {len(submission)} predictions\")\n",
    "print(f\"Prediction range: {test_predictions.min():.4f} - {test_predictions.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "What patterns distinguish violations from non-violations across both rules\n",
    "Which features transfer between different rule types\n",
    "How to build rule-agnostic violation detectors\n",
    "What the provided rule examples teach us about generalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jigsaw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
